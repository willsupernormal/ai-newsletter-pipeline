# AI Newsletter Pipeline - START HERE

> **New to this project? Read this first.** This document provides a complete overview and guides you to all relevant documentation.

**Last Updated:** October 29, 2025  
**Status:** âœ… Operational  
**Version:** 2.0 (Post-Cleanup)

---

## ğŸ“‹ **Quick Navigation**

| Document | Purpose | When to Read |
|----------|---------|--------------|
| **[START_HERE.md](START_HERE.md)** | Project overview & navigation | First time here |
| **[README.md](README.md)** | Technical overview & architecture | Understanding the system |
| **[PROJECT_STATUS.md](PROJECT_STATUS.md)** | Current state & known issues | Checking system health |
| **[docs/SETUP.md](docs/SETUP.md)** | Complete setup instructions | Setting up from scratch |
| **[docs/OPERATIONS.md](docs/OPERATIONS.md)** | Running & troubleshooting | Daily operations |
| **[AIRTABLE_DATA_SPEC.md](AIRTABLE_DATA_SPEC.md)** | Data structure reference | Understanding data flow |

---

## ğŸ¯ **What This System Does**

### **In One Sentence:**
Automatically scrapes 31 AI news sources daily, uses GPT-4 to select the top 5 articles, posts them to Slack with interactive buttons, and allows one-click addition to an Airtable content pipeline.

### **The Flow:**
```
1. GitHub Actions runs at 7 AM AEST
   â†“
2. Scrapes 31 RSS feeds â†’ ~180 articles
   â†“
3. AI filters in 2 stages â†’ Top 5 articles
   â†“
4. Posts to Slack #ai-daily-digest
   â†“
5. User clicks "Add to Pipeline" button
   â†“
6. Article added to Airtable with full content
```

---

## ğŸ“ **Project Structure**

```
ai-newsletter-pipeline/
â”‚
â”œâ”€â”€ ğŸ“„ START_HERE.md              â† You are here
â”œâ”€â”€ ğŸ“„ README.md                  â† Technical overview
â”œâ”€â”€ ğŸ“„ PROJECT_STATUS.md          â† Current state & issues
â”œâ”€â”€ ğŸ“„ AIRTABLE_DATA_SPEC.md      â† Data structure
â”œâ”€â”€ ğŸ“„ requirements.txt           â† Python dependencies
â”œâ”€â”€ ğŸ“„ .env.example               â† Environment variables template
â”‚
â”œâ”€â”€ ğŸ“ docs/                      â† All documentation
â”‚   â”œâ”€â”€ SETUP.md                  â† Complete setup guide
â”‚   â”œâ”€â”€ OPERATIONS.md             â† Running & troubleshooting
â”‚   â”œâ”€â”€ GITHUB_ACTIONS_SETUP.md   â† CI/CD configuration
â”‚   â”œâ”€â”€ LOCAL_TESTING_GUIDE.md    â† Testing locally
â”‚   â””â”€â”€ AIRTABLE_COMPLETE_SETUP.md â† Airtable configuration
â”‚
â”œâ”€â”€ ğŸ“ scripts/                   â† Utility scripts
â”‚   â”œâ”€â”€ run_ai_digest_pipeline.py â† Main entry point
â”‚   â”œâ”€â”€ add_rss_source.py         â† Manage RSS sources
â”‚   â”œâ”€â”€ fix_and_add_sources.py    â† Fix blocked sources
â”‚   â””â”€â”€ run_rss_pipeline.py       â† RSS-only pipeline
â”‚
â”œâ”€â”€ ğŸ“ api/                       â† Webhook server
â”‚   â””â”€â”€ webhook_server.py         â† FastAPI server for Slack
â”‚
â”œâ”€â”€ ğŸ“ config/                    â† Configuration
â”‚   â””â”€â”€ settings.py               â† Settings management
â”‚
â”œâ”€â”€ ğŸ“ database/                  â† Database clients
â”‚   â”œâ”€â”€ supabase_simple.py        â† Supabase client
â”‚   â””â”€â”€ digest_storage.py         â† Digest storage logic
â”‚
â”œâ”€â”€ ğŸ“ scrapers/                  â† Content scrapers
â”‚   â”œâ”€â”€ rss_scraper.py            â† RSS feed scraping
â”‚   â””â”€â”€ article_scraper.py        â† Full article extraction
â”‚
â”œâ”€â”€ ğŸ“ processors/                â† Content processors
â”‚   â”œâ”€â”€ multi_stage_digest.py     â† AI filtering logic
â”‚   â”œâ”€â”€ deduplicator.py           â† Deduplication
â”‚   â””â”€â”€ data_aggregator.py        â† Data aggregation
â”‚
â”œâ”€â”€ ğŸ“ services/                  â† External services
â”‚   â”œâ”€â”€ airtable_client.py        â† Airtable integration
â”‚   â”œâ”€â”€ slack_notifier.py         â† Slack posting
â”‚   â”œâ”€â”€ slack_webhook_handler.py  â† Slack button handling
â”‚   â””â”€â”€ prompt_service.py         â† AI prompts
â”‚
â””â”€â”€ ğŸ“ .github/workflows/         â† GitHub Actions
    â””â”€â”€ daily-scrape.yml          â† Daily automation
```

---

## ğŸ”§ **Tech Stack**

### **Infrastructure:**
- **GitHub Actions** - Daily scheduling (7 AM AEST)
- **Railway** - Webhook server hosting (Slack buttons)
- **Supabase** - PostgreSQL database (articles, digests, sources)
- **Airtable** - Content pipeline management

### **Core Technologies:**
- **Python 3.11** - Main language
- **FastAPI** - Webhook server
- **OpenAI GPT-4** - AI filtering & analysis
- **aiohttp** - Async HTTP requests
- **feedparser** - RSS parsing
- **newspaper3k/trafilatura** - Article extraction

### **Key Libraries:**
```python
# Web scraping
aiohttp, feedparser, beautifulsoup4, brotli

# Database
supabase, asyncpg

# AI
openai, tiktoken

# External services
pyairtable, fastapi, uvicorn

# Utilities
python-dotenv, pydantic, structlog
```

---

## ğŸš€ **Quick Start Commands**

### **Run Digest Locally:**
```bash
cd /path/to/ai-newsletter-pipeline
python3 scripts/run_ai_digest_pipeline.py
```

### **Force Regenerate Today's Digest:**
```bash
python3 scripts/run_ai_digest_pipeline.py force
```

### **Manage RSS Sources:**
```bash
# List all sources
python3 scripts/add_rss_source.py list

# Add new source
python3 scripts/add_rss_source.py add "Source Name" "https://example.com/feed.xml"

# Disable source
python3 scripts/add_rss_source.py disable "Source Name"

# Enable source
python3 scripts/add_rss_source.py enable "Source Name"
```

### **Fix Blocked Sources:**
```bash
python3 scripts/fix_and_add_sources.py
```

---

## ğŸ“Š **System Health**

### **Current Metrics:**
- **RSS Sources:** 31 active
- **Articles Collected:** ~180 per day (target)
- **Success Rate:** ~90%
- **Final Selection:** 5 articles
- **Slack Posts:** Daily at 7 AM AEST
- **Button Success Rate:** 100%

### **Known Issues:**
1. Some RSS sources have broken URLs (see PROJECT_STATUS.md)
2. Airtable fields may not fully populate (under investigation)

---

## ğŸ”‘ **Environment Variables**

### **Required:**
```bash
# Supabase (Database)
SUPABASE_URL=https://xxx.supabase.co
SUPABASE_KEY=xxx

# OpenAI (AI Filtering)
OPENAI_API_KEY=sk-xxx

# Slack (Posting & Buttons)
SLACK_BOT_TOKEN=xoxb-xxx
SLACK_SIGNING_SECRET=xxx
SLACK_WEBHOOK_URL=https://hooks.slack.com/services/xxx

# Airtable (Content Pipeline)
AIRTABLE_API_KEY=xxx
AIRTABLE_BASE_ID=xxx
AIRTABLE_TABLE_NAME=Content Pipeline
```

### **Optional:**
```bash
# RSS Settings
RSS_REQUEST_TIMEOUT=30
RSS_MAX_RETRIES=3
MAX_ARTICLES_PER_SOURCE=50

# AI Settings
OPENAI_MODEL=gpt-4-turbo-preview
STAGE1_TARGET_COUNT=10
STAGE2_TARGET_COUNT=5
```

**See `.env.example` for complete list.**

---

## ğŸ“– **Documentation Guide**

### **For First-Time Setup:**
1. Read [START_HERE.md](START_HERE.md) (this file)
2. Read [docs/SETUP.md](docs/SETUP.md)
3. Configure environment variables
4. Run test digest

### **For Daily Operations:**
1. Check [PROJECT_STATUS.md](PROJECT_STATUS.md) for current state
2. Use [docs/OPERATIONS.md](docs/OPERATIONS.md) for troubleshooting
3. Check GitHub Actions logs for errors

### **For Development:**
1. Read [README.md](README.md) for architecture
2. Read [AIRTABLE_DATA_SPEC.md](AIRTABLE_DATA_SPEC.md) for data structure
3. Check [docs/LOCAL_TESTING_GUIDE.md](docs/LOCAL_TESTING_GUIDE.md)

### **For Understanding Data:**
1. Read [AIRTABLE_DATA_SPEC.md](AIRTABLE_DATA_SPEC.md)
2. Check Supabase schema in [docs/SETUP.md](docs/SETUP.md)
3. Review `database/` directory for storage logic

---

## ğŸ¯ **Common Tasks**

### **"I want to add a new RSS source"**
```bash
python3 scripts/add_rss_source.py add "Source Name" "https://example.com/feed.xml"
```
See [docs/OPERATIONS.md](docs/OPERATIONS.md) for details.

### **"I want to test the digest"**
```bash
python3 scripts/run_ai_digest_pipeline.py force
```
See [docs/LOCAL_TESTING_GUIDE.md](docs/LOCAL_TESTING_GUIDE.md) for details.

### **"I want to check what's broken"**
Read [PROJECT_STATUS.md](PROJECT_STATUS.md) â†’ Known Issues section.

### **"I want to understand the data flow"**
Read [AIRTABLE_DATA_SPEC.md](AIRTABLE_DATA_SPEC.md) â†’ Complete Flow section.

### **"I want to deploy changes"**
```bash
git add .
git commit -m "Description"
git push origin main
```
GitHub Actions and Railway auto-deploy.

---

## ğŸ” **Key Concepts**

### **1. Multi-Stage AI Filtering**
- **Stage 1:** GPT-4 reviews all articles, selects top 10 based on relevance
- **Stage 2:** GPT-4 reviews top 10, selects final 5 with summaries
- **Why 2 stages?** Better quality, more diverse selection

### **2. Async Button Processing**
- User clicks "Add to Pipeline" in Slack
- Button immediately shows "Processing..." (no timeout)
- Background task: Fetch â†’ Scrape â†’ Push to Airtable
- Button updates to "âœ… Added" when complete

### **3. RSS Source Management**
- Sources stored in Supabase `content_sources` table
- Can enable/disable sources without code changes
- Tracks success/failure counts
- Browser-like headers to avoid 403 errors

### **4. Deduplication**
- URLs are unique in database
- Duplicate articles automatically skipped
- Prevents re-processing same content

---

## ğŸš¨ **Troubleshooting**

### **"Digest didn't run today"**
1. Check GitHub Actions logs
2. Verify environment variables in GitHub Secrets
3. Check Supabase connection

### **"Slack buttons not working"**
1. Check Railway logs
2. Verify SLACK_SIGNING_SECRET matches
3. Test webhook URL

### **"Articles not in Airtable"**
1. Check Railway logs for errors
2. Verify AIRTABLE_API_KEY
3. Check field mappings in code

### **"RSS sources failing"**
1. Check logs for specific errors
2. Verify URLs are correct
3. Install brotli if needed: `pip3 install brotli`
4. Disable broken sources

**For detailed troubleshooting, see [docs/OPERATIONS.md](docs/OPERATIONS.md)**

---

## ğŸ“ **Getting Help**

### **Check Logs:**
- **GitHub Actions:** https://github.com/willsupernormal/ai-newsletter-pipeline/actions
- **Railway:** https://railway.app (webhook server)
- **Supabase:** https://supabase.com (database)

### **Check Status:**
- Read [PROJECT_STATUS.md](PROJECT_STATUS.md)
- Check GitHub Actions for recent runs
- Check Railway for webhook errors

### **Common Issues:**
- See [docs/OPERATIONS.md](docs/OPERATIONS.md) â†’ Troubleshooting section
- See [PROJECT_STATUS.md](PROJECT_STATUS.md) â†’ Known Issues section

---

## ğŸ“š **Learning Path**

### **Level 1: Understanding (30 minutes)**
1. Read this file (START_HERE.md)
2. Read [README.md](README.md)
3. Read [PROJECT_STATUS.md](PROJECT_STATUS.md)

### **Level 2: Setup (1-2 hours)**
1. Read [docs/SETUP.md](docs/SETUP.md)
2. Configure environment variables
3. Run test digest locally

### **Level 3: Operations (ongoing)**
1. Read [docs/OPERATIONS.md](docs/OPERATIONS.md)
2. Monitor GitHub Actions
3. Manage RSS sources as needed

### **Level 4: Development (as needed)**
1. Read [AIRTABLE_DATA_SPEC.md](AIRTABLE_DATA_SPEC.md)
2. Review code in `scrapers/`, `processors/`, `services/`
3. Read [docs/LOCAL_TESTING_GUIDE.md](docs/LOCAL_TESTING_GUIDE.md)

---

## âœ… **System Checklist**

### **Daily:**
- [ ] Check Slack for digest post (7 AM AEST)
- [ ] Verify 5 articles selected
- [ ] Test "Add to Pipeline" button if needed

### **Weekly:**
- [ ] Review GitHub Actions logs
- [ ] Check RSS source health
- [ ] Review Airtable for new articles

### **Monthly:**
- [ ] Review source performance
- [ ] Add new sources if needed
- [ ] Update documentation if changed

---

## ğŸ‰ **Recent Improvements**

### **October 2025:**
- âœ… Fixed Slack timeout (async processing)
- âœ… Added button state feedback
- âœ… Added 17 new premium sources
- âœ… Added browser headers for scraping
- âœ… Installed brotli for compression
- âœ… Major codebase cleanup (-69% lines)
- âœ… Reorganized into proper structure
- âœ… Updated all documentation

---

## ğŸ“ **Version History**

- **v2.0** (Oct 2025) - Major cleanup, 31 sources, async buttons
- **v1.5** (Sep 2025) - Airtable integration, Slack buttons
- **v1.0** (Aug 2025) - Initial release, basic digest

---

## ğŸ”— **External Links**

- **GitHub Repository:** https://github.com/willsupernormal/ai-newsletter-pipeline
- **Railway Dashboard:** https://railway.app
- **Supabase Dashboard:** https://supabase.com
- **Airtable Base:** [Your Airtable URL]
- **Slack Workspace:** [Your Slack URL]

---

## ğŸ’¡ **Pro Tips**

1. **Always check PROJECT_STATUS.md first** - It has the current state
2. **Use `force` flag for testing** - Regenerates today's digest
3. **Check Railway logs for button issues** - Most detailed logging
4. **Disable broken sources quickly** - Don't let them slow down scraping
5. **Monitor source success rates** - In Supabase `content_sources` table

---

## ğŸ¯ **Next Steps**

### **If you're new:**
â†’ Read [docs/SETUP.md](docs/SETUP.md) to get started

### **If you're debugging:**
â†’ Read [PROJECT_STATUS.md](PROJECT_STATUS.md) for known issues

### **If you're developing:**
â†’ Read [README.md](README.md) for architecture

### **If you're operating:**
â†’ Read [docs/OPERATIONS.md](docs/OPERATIONS.md) for daily tasks

---

**Welcome to the AI Newsletter Pipeline! ğŸš€**

**Questions?** Check the documentation links above or review the code in the relevant directories.

